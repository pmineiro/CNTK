########################################################################
# Attention version of experiment 8
########################################################################

########################################################################
#  (All clues, uniform average) <- maxlayer 1 (?)
#  
#  Finished Epoch[16 of 200]: [Training] ce = 0.01668583 * 15620; errs = 0.128% * 15620; totalSamplesSeen = 249920; learningRatePerSample = 0.0099999998; epochTime=3084.34s
#  Finished Epoch[16 of 200]: [Validate] ce = 1.75745921 * 2368; errs = 35.051% * 2368
#
#  (attention maxlayer 0)
#  Finished Epoch[20 of 200]: [Training] ce = 0.04184388 * 15620; errs = 0.384% * 15620; totalSamplesSeen = 312400; learningRatePerSample = 0.011801452; epochTime=1954.55s
#  Finished Epoch[20 of 200]: [Validate] ce = 1.21401321 * 2368; errs = 24.916% * 2368
#
#  (attention maxlayer 1)
# Finished Epoch[30 of 200]: [Training] ce = 0.40486634 * 15620; errs = 10.691% * 15620; totalSamplesSeen = 468600; learningRatePerSample = 0.011801452; epochTime=3264.13s
# Finished Epoch[30 of 200]: [Validate] ce = 1.14176705 * 2368; errs = 20.608% * 2368
# 
########################################################################

RunRootDir = ".."      # default if not overridden
DataDir    = "$RunRootDir$/Data"
OutDir     = "$RunRootDir$/Out"

command = train

deviceId = auto 
ExpId = quizbowl-9

modelPath  = "$OutDir$/$ExpId$/QuizBowl.dnn"
stderr     = "$OutDir$/$ExpId$/QuizBowl"

inputVocabDim = 70911
labelDim = 2370
hiddenDim = 160
embeddingDim = 160
maxLayer = 1
minibatchSize=128
learningRatesPerSample = 0.05
momentumPerMB = 0.0
dropoutRate = 0.5
restartFrom = "/dev/null"

#---------------------------
# network
#---------------------------
#
BrainScriptNetworkBuilder = (if "$restartFrom$" == "/dev/null"
then (new ComputationNetwork [
  include "GRU.bs"

  inputVocabDim = $inputVocabDim$
  labelDim = $labelDim$
  hiddenDim = $hiddenDim$
  embeddingDim = $embeddingDim$
  precision = "float"
  maxLayer = $maxLayer$
  
  netDims[i:0..maxLayer] = hiddenDim

  inputAxis = DynamicAxis()
  Word = Input (inputVocabDim, dynamicAxis=inputAxis, tag='feature')
  Answer = Input (labelDim, tag='label')
  
  Einput = BS.Parameters.WeightParam ($inputVocabDim$, embeddingDim)
  inputEmbedded = TransposeTimes (Einput, Word)
  net = RecurrentBiresidualGRUStack (netDims, inputEmbedded, inputDim=embeddingDim, addDropout=true)
  netOutput = net[Length (netDims) - 1].h
  attV = Parameter (hiddenDim, 1, init='fixedValue', value=0.0)
  attPre = FlattenDimensions (TransposeTimes (attV, netOutput), 1, 2)
  SoftMaxOverSequence (z) = [
    runningLogSum = BS.LogPlus (z, PastValue (0, runningLogSum, defaultHiddenActivation=-1e30))
    logSum = BS.Boolean.If (BS.Loop.IsLast (runningLogSum),    # if last entry
                   /*then*/ runningLogSum,                     # then copy that
                   /*else*/ FutureValue (0, logSum))           # else just propagate to the front
    result = Exp (z - logSum)
  ].result
  attSoft = SoftMaxOverSequence (attPre)
  weightedNetOutput = ElementTimes (attSoft, Dropout (netOutput))
  avgNetOutput = [
    mysum = weightedNetOutput + PastValue (0, mysum, defaultHiddenActivation=0)
  ].mysum
  lastAvgNetOutput = BS.Sequences.Last (avgNetOutput)

  wOutput = BS.Parameters.WeightParam (net[Length (netDims) - 1].dim, $labelDim$)
  bOutput = BS.Parameters.BiasParam ($labelDim$)
  prePreSoftMax = TransposeTimes (wOutput, lastAvgNetOutput) 
  preSoftMax = prePreSoftMax + bOutput
  recPreSoftMax = ReconcileDynamicAxis (preSoftMax, Answer)
  ce = CrossEntropyWithSoftmax (Answer, recPreSoftMax, tag='criterion')
  errs = ErrorPrediction (Answer, recPreSoftMax, tag='evaluation')
])
else
(BS.Network.Load ("$restartFrom$"))
)

train = [
  action = "train"
  traceLevel = 1
  epochSize = 0

  reader = [
    readerType = "CNTKTextFormatReader"
    file = "$DataDir$/quizbowl.train"
    randomize = "true"

    input = [ 
      Word = [ 
        dim = "$inputVocabDim$"
        format = "sparse"
      ]
      Answer = [
        dim = "$labelDim$"
        format = "sparse"
      ]
    ]
  ]

  cvReader = [
    readerType = "CNTKTextFormatReader"
    file = "$DataDir$/quizbowl.dev"
    randomize = "false"

    input = [ 
      Word = [ 
        dim = "$inputVocabDim$"
        format = "sparse"
      ]
      Answer = [
        dim = "$labelDim$"
        format = "sparse"
      ]
    ]
  ]

  SGD = [ 
    modelPath = "$modelPath$"
    epochSize = 0
    keepCheckPointFiles = "false"
    maxEpochs = 200
    minibatchSize = $minibatchSize$
    learningRatesPerSample = $learningRatesPerSample$
    momentumPerMB = $momentumPerMB$
    dropoutRate = $dropoutRate$
    gradUpdateType = "None"

    # settings for Auto Adjust Learning Rate
    AutoAdjust = [
        autoAdjustLR = "adjustAfterEpoch"
    ]
  ]
]

test = [
  action = "eval"

  minibatchSize = 1024
  traceLevel = 1
  epochSize = 0

  reader = [
    readerType = "CNTKTextFormatReader"
    file = "$DataDir$/quizbowl.test"
    randomize = "false"

    input = [ 
      Word = [ 
        dim = "$inputVocabDim$"
        format = "sparse"
      ]
      Answer = [
        dim = "$labelDim$"
        format = "sparse"
      ]
    ]
  ]
]
