########################################################################
#
# gets 2% / 55% train / dev error on last sentence all categories
#
########################################################################


RunRootDir = ".."      # default if not overridden
DataDir    = "$RunRootDir$/Data"
OutDir     = "$RunRootDir$/Out"

command = train

deviceId = auto 
ExpId = quizbowl-2

modelPath  = "$OutDir$/$ExpId$/QuizBowl.dnn"
stderr     = "$OutDir$/$ExpId$/QuizBowl"

inputVocabDim = 26898
labelDim = 2370
hiddenDim = 60
embeddingDim = 50
maxLayer = 1

#---------------------------
# network
#---------------------------

BrainScriptNetworkBuilder = (new ComputationNetwork [
  inputVocabDim = $inputVocabDim$
  labelDim = $labelDim$
  hiddenDim = $hiddenDim$
  embeddingDim = $embeddingDim$
  precision = "float"
  maxLayer = $maxLayer$
  
  netDims[i:0..maxLayer] = hiddenDim

  inputAxis = DynamicAxis()
  Word = Input (inputVocabDim, dynamicAxis=inputAxis, tag='feature')
  Answer = Input (labelDim, tag='label')
  
  Einput = BS.Parameters.WeightParam ($inputVocabDim$, embeddingDim)
  inputEmbedded = TransposeTimes (Einput, Word)
  net = BS.RNNs.RecurrentBirectionalLSTMPStack (netDims, cellDims=netDims, inputEmbedded, inputDim=embeddingDim)
  netOutput = BS.Sequences.Last (net[Length (netDims) - 1].h)

  wOutput = BS.Parameters.WeightParam (2*$hiddenDim$, $labelDim$)
  bOutput = BS.Parameters.BiasParam ($labelDim$)
  prePreSoftMax = TransposeTimes (wOutput, netOutput) 
  preSoftMax = prePreSoftMax + bOutput
  recPreSoftMax = ReconcileDynamicAxis (preSoftMax, Answer)
  ce = CrossEntropyWithSoftmax (Answer, recPreSoftMax, tag='criterion')
  errs = ErrorPrediction (Answer, recPreSoftMax, tag='evaluation')
])

train = [
  action = "train"
  traceLevel = 1
  epochSize = 0

  reader = [
    readerType = "CNTKTextFormatReader"
    file = "$DataDir$/quizbowl.train"
    randomize = "true"

    input = [ 
      Word = [ 
        dim = "$inputVocabDim$"
        format = "sparse"
      ]
      Answer = [
        dim = "$labelDim$"
        format = "sparse"
      ]
    ]
  ]

  cvReader = [
    readerType = "CNTKTextFormatReader"
    file = "$DataDir$/quizbowl.dev"
    randomize = "false"

    input = [ 
      Word = [ 
        dim = "$inputVocabDim$"
        format = "sparse"
      ]
      Answer = [
        dim = "$labelDim$"
        format = "sparse"
      ]
    ]
  ]

  SGD = [ 
    modelPath = "$modelPath$"
    epochSize = 0
    keepCheckPointFiles = "false"
    maxEpochs = 100
    minibatchSize = 128
    learningRatesPerSample = 0.1
    momentumAsTimeConstant = 0.0
    dropoutRate = 0.0
    gradUpdateType = "None"

    # settings for Auto Adjust Learning Rate
    AutoAdjust = [
        autoAdjustLR = "adjustAfterEpoch"
        reduceLearnRateIfImproveLessThan = 0
        continueReduce = false
        increaseLearnRateIfImproveMoreThan = 1000000000
        learnRateDecreaseFactor = 0.5
        learnRateIncreaseFactor = 1.382
        learnRateAdjustInterval = 5
    ]
  ]
]

test = [
  action = "eval"

  minibatchSize = 1024
  traceLevel = 1
  epochSize = 0

  reader = [
    readerType = "CNTKTextFormatReader"
    file = "$DataDir$/quizbowl.test"
    randomize = "false"

    input = [ 
      Word = [ 
        dim = "$inputVocabDim$"
        format = "sparse"
      ]
      Answer = [
        dim = "$labelDim$"
        format = "sparse"
      ]
    ]
  ]
]
